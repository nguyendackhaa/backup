#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
C√†o d·ªØ li·ªáu t·ª´ website Fotek.com.tw
Ph√°t tri·ªÉn b·ªüi: Assistant AI
Ch·ª©c nƒÉng: C√†o d·ªØ li·ªáu s·∫£n ph·∫©m t·ª´ Fotek.com.tw v·ªõi ƒëa lu·ªìng v√† AI Gemini
"""

import requests
import json
import os
import time
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urljoin, urlparse
from pathlib import Path
import pandas as pd
from PIL import Image, ImageDraw
import io
import base64
import re
from typing import List, Dict, Optional, Tuple
import logging

# Th∆∞ vi·ªán cho web scraping
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# Th∆∞ vi·ªán cho AI Gemini
import google.generativeai as genai

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FotekScraper:
    """Class ch√≠nh cho vi·ªác c√†o d·ªØ li·ªáu t·ª´ Fotek.com.tw"""
    
    def __init__(self, max_workers: int = 5):
        """
        Kh·ªüi t·∫°o FotekScraper
        
        Args:
            max_workers: S·ªë l∆∞·ª£ng lu·ªìng t·ªëi ƒëa ƒë·ªÉ x·ª≠ l√Ω song song
        """
        self.base_url = "https://www.fotek.com.tw"
        self.max_workers = max_workers
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # C·∫•u h√¨nh Selenium WebDriver
        self.chrome_options = Options()
        self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        # C·∫•u h√¨nh Gemini AI v·ªõi API key ƒë∆∞·ª£c embed
        gemini_api_key = "AIzaSyBEUiHyq0bBFW_6TRF9g-pmjG3_jQfPpBY"
        try:
            genai.configure(api_key=gemini_api_key)
            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("‚úÖ Gemini AI ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")
        except Exception as e:
            self.gemini_model = None
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ kh·ªüi t·∫°o Gemini AI: {e}")
        
        # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ
        self.output_dir = Path("fotek_data")
        self.images_dir = self.output_dir / "images"
        self.specs_dir = self.output_dir / "specifications"
        self.excel_dir = self.output_dir / "excel"
        
        for dir_path in [self.output_dir, self.images_dir, self.specs_dir, self.excel_dir]:
            dir_path.mkdir(exist_ok=True, parents=True)
        
        logger.info("FotekScraper ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")
    
    def get_driver(self) -> webdriver.Chrome:
        """T·∫°o m·ªôt WebDriver Chrome m·ªõi"""
        try:
            driver = webdriver.Chrome(options=self.chrome_options)
            driver.implicitly_wait(10)
            return driver
        except Exception as e:
            logger.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o WebDriver: {e}")
            raise
    
    def close_driver(self, driver: webdriver.Chrome):
        """ƒê√≥ng WebDriver"""
        try:
            driver.quit()
        except Exception as e:
            logger.warning(f"L·ªói khi ƒë√≥ng WebDriver: {e}")
    
    def safe_request(self, url: str, timeout: int = 30) -> Optional[requests.Response]:
        """Th·ª±c hi·ªán request an to√†n v·ªõi retry"""
        for attempt in range(3):
            try:
                response = self.session.get(url, timeout=timeout)
                response.raise_for_status()
                return response
            except requests.RequestException as e:
                logger.warning(f"L·ªói request (l·∫ßn {attempt + 1}): {e}")
                if attempt == 2:
                    return None
                time.sleep(2 ** attempt)
        return None
    
    def extract_series_links(self, category_url: str) -> List[Dict[str, str]]:
        """
        Tr√≠ch xu·∫•t c√°c link series s·∫£n ph·∫©m t·ª´ trang danh m·ª•c
        
        Args:
            category_url: URL c·ªßa trang danh m·ª•c
            
        Returns:
            List c√°c dict ch·ª©a th√¥ng tin series (name, url, image)
        """
        logger.info(f"B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t series t·ª´: {category_url}")
        
        response = self.safe_request(category_url)
        if not response:
            logger.error(f"Kh√¥ng th·ªÉ truy c·∫≠p trang danh m·ª•c: {category_url}")
            return []
        
        soup = BeautifulSoup(response.content, 'html.parser')
        series_list = []
        
        # T√¨m section ch·ª©a c√°c series
        bg_light_section = soup.find('section', class_='bg-light')
        if not bg_light_section:
            logger.error("Kh√¥ng t√¨m th·∫•y section bg-light")
            return []
        
        # T√¨m t·∫•t c·∫£ c√°c card series
        cards = bg_light_section.find_all('div', class_='card mb-4')
        logger.info(f"T√¨m th·∫•y {len(cards)} series cards")
        
        for card in cards:
            try:
                # Tr√≠ch xu·∫•t t√™n series
                title_element = card.find('h4')
                series_name = title_element.text.strip() if title_element else "Unknown Series"
                
                # Tr√≠ch xu·∫•t link
                link_element = card.find('a', class_='stretched-link')
                if not link_element or not link_element.get('href'):
                    continue
                
                series_url = urljoin(self.base_url, link_element['href'])
                
                # Tr√≠ch xu·∫•t ·∫£nh series
                img_div = card.find('div', class_='box-img')
                series_image = ""
                if img_div and img_div.get('style'):
                    style = img_div['style']
                    match = re.search(r"background-image:url\('([^']+)'\)", style)
                    if match:
                        series_image = urljoin(self.base_url, match.group(1))
                
                # Tr√≠ch xu·∫•t m√¥ t·∫£
                description_element = card.find('p', class_='txt-l3')
                description = description_element.text.strip() if description_element else ""
                
                series_info = {
                    'name': series_name,
                    'url': series_url,
                    'image': series_image,
                    'description': description
                }
                
                series_list.append(series_info)
                logger.info(f"ƒê√£ tr√≠ch xu·∫•t series: {series_name}")
                
            except Exception as e:
                logger.error(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin series: {e}")
                continue
        
        logger.info(f"Ho√†n th√†nh tr√≠ch xu·∫•t {len(series_list)} series")
        return series_list
    
    def extract_products_from_series(self, series_url: str) -> List[Dict[str, str]]:
        """
        Tr√≠ch xu·∫•t danh s√°ch s·∫£n ph·∫©m t·ª´ trang series
        
        Args:
            series_url: URL c·ªßa trang series
            
        Returns:
            List c√°c dict ch·ª©a th√¥ng tin s·∫£n ph·∫©m c∆° b·∫£n
        """
        logger.info(f"B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t s·∫£n ph·∫©m t·ª´ series: {series_url}")
        
        # S·ª≠ d·ª•ng Selenium thay v√¨ requests ƒë·ªÉ x·ª≠ l√Ω JavaScript
        driver = self.get_driver()
        try:
            driver.get(series_url)
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # L·∫•y HTML sau khi JavaScript ƒë√£ load
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            products_list = []
            
            # T√¨m container ch·ª©a c√°c s·∫£n ph·∫©m v·ªõi selector linh ho·∫°t h∆°n
            container = soup.find('div', class_='container') or soup.find('div', {'class': re.compile(r'.*container.*')})
            if not container:
                logger.error("Kh√¥ng t√¨m th·∫•y container s·∫£n ph·∫©m")
                return []
            
            # T√¨m t·∫•t c·∫£ c√°c item-type (nh√≥m s·∫£n ph·∫©m) v·ªõi selector linh ho·∫°t
            item_types = (container.find_all('div', class_='item-type') or 
                         container.find_all('div', {'class': re.compile(r'.*item.*type.*')}) or
                         container.find_all('div', {'class': re.compile(r'.*product.*group.*')}))
            
            logger.info(f"T√¨m th·∫•y {len(item_types)} nh√≥m s·∫£n ph·∫©m")
            
            # N·∫øu kh√¥ng t√¨m th·∫•y item-type, th·ª≠ t√¨m tr·ª±c ti·∫øp danh s√°ch s·∫£n ph·∫©m
            if not item_types:
                logger.warning("Kh√¥ng t√¨m th·∫•y item-type, th·ª≠ t√¨m tr·ª±c ti·∫øp s·∫£n ph·∫©m...")
                # T√¨m t·∫•t c·∫£ c√°c link c√≥ ch·ª©a "product" ho·∫∑c "View specs"
                product_links = soup.find_all('a', href=re.compile(r'/product/\d+'))
                
                for link in product_links:
                    try:
                        product_url = urljoin(self.base_url, link['href'])
                        
                        # T√¨m th√¥ng tin s·∫£n ph·∫©m t·ª´ context
                        parent = link.find_parent('li') or link.find_parent('div')
                        if parent:
                            spans = parent.find_all('span')
                            if len(spans) >= 2:
                                product_code = spans[0].text.strip()
                                features = spans[1].text.strip() if len(spans) > 1 else ""
                                
                                product_info = {
                                    'code': product_code,
                                    'features': features,
                                    'url': product_url,
                                    'group_name': "Unknown Group",
                                    'group_image': "",
                                    'series_url': series_url
                                }
                                
                                products_list.append(product_info)
                                logger.debug(f"ƒê√£ tr√≠ch xu·∫•t s·∫£n ph·∫©m: {product_code}")
                    except Exception as e:
                        logger.warning(f"L·ªói khi tr√≠ch xu·∫•t s·∫£n ph·∫©m t·ª´ link: {e}")
                        continue
            else:
                # X·ª≠ l√Ω theo c√°ch c≈© n·∫øu t√¨m th·∫•y item-type
                for item_type in item_types:
                    try:
                        # L·∫•y t√™n nh√≥m s·∫£n ph·∫©m
                        group_name_element = item_type.find('h5') or item_type.find('h4') or item_type.find('h3')
                        group_name = group_name_element.text.strip() if group_name_element else "Unknown Group"
                        
                        # L·∫•y ·∫£nh nh√≥m
                        img_div = item_type.find('div', class_='box-img') or item_type.find('div', {'class': re.compile(r'.*img.*')})
                        group_image = ""
                        if img_div and img_div.get('style'):
                            style = img_div['style']
                            match = re.search(r"background-image:url\('([^']+)'\)", style)
                            if match:
                                group_image = urljoin(self.base_url, match.group(1))
                        
                        # T√¨m t·∫•t c·∫£ s·∫£n ph·∫©m trong nh√≥m
                        product_items = item_type.find_all('li')
                        
                        for li in product_items:
                            spans = li.find_all('span')
                            if len(spans) >= 3:
                                product_code = spans[0].text.strip()
                                features = spans[1].text.strip()
                                
                                # T√¨m link "View specs"
                                specs_link_element = spans[2].find('a')
                                if specs_link_element and specs_link_element.get('href'):
                                    product_url = urljoin(self.base_url, specs_link_element['href'])
                                    
                                    product_info = {
                                        'code': product_code,
                                        'features': features,
                                        'url': product_url,
                                        'group_name': group_name,
                                        'group_image': group_image,
                                        'series_url': series_url
                                    }
                                    
                                    products_list.append(product_info)
                                    logger.debug(f"ƒê√£ tr√≠ch xu·∫•t s·∫£n ph·∫©m: {product_code}")
                        
                    except Exception as e:
                        logger.error(f"L·ªói khi tr√≠ch xu·∫•t nh√≥m s·∫£n ph·∫©m: {e}")
                        continue
            
            logger.info(f"Ho√†n th√†nh tr√≠ch xu·∫•t {len(products_list)} s·∫£n ph·∫©m t·ª´ series")
            return products_list
            
        except Exception as e:
            logger.error(f"L·ªói khi tr√≠ch xu·∫•t s·∫£n ph·∫©m t·ª´ series {series_url}: {e}")
            return []
        finally:
            self.close_driver(driver)
    
    def extract_product_details(self, product_url: str, product_code: str) -> Dict:
        """
        Tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m t·ª´ trang s·∫£n ph·∫©m
        
        Args:
            product_url: URL c·ªßa trang s·∫£n ph·∫©m
            product_code: M√£ s·∫£n ph·∫©m
            
        Returns:
            Dict ch·ª©a th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m
        """
        logger.info(f"B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m: {product_code}")
        
        driver = self.get_driver()
        try:
            driver.get(product_url)
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # L·∫•y HTML sau khi JavaScript ƒë√£ load
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            
            product_details = {
                'code': product_code,
                'url': product_url,
                'name': '',
                'name_vietnamese': '',
                'images': {
                    'product': [],
                    'specifications': '',
                    'wiring_diagram': '',
                    'dimensions': ''
                },
                'specifications_table': '',
                'specifications_raw': ''
            }
            
            # Tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m
            title_element = (soup.find('p', class_='title-card') or 
                            soup.find('h1') or 
                            soup.find('h2') or
                            soup.find('div', {'class': re.compile(r'.*title.*')}))
            if title_element:
                product_details['name'] = title_element.text.strip()
            
            # Tr√≠ch xu·∫•t ·∫£nh s·∫£n ph·∫©m ch√≠nh
            gallery = soup.find('div', class_='gallery') or soup.find('div', {'class': re.compile(r'.*gallery.*')})
            if gallery:
                product_images = []
                for item in gallery.find_all('div', class_='item'):
                    link = item.find('a')
                    if link and link.get('href'):
                        img_url = urljoin(self.base_url, link['href'])
                        product_images.append(img_url)
                product_details['images']['product'] = product_images
            
            # Tr√≠ch xu·∫•t th√¥ng tin t·ª´ c√°c tab
            tab_content = soup.find('div', class_='tab-content') or soup.find('div', {'id': 'myTabContent'})
            if tab_content:
                # Tab specifications (tab1)
                tab1 = tab_content.find('div', id='tab1')
                if tab1:
                    img_element = tab1.find('img')
                    if img_element and img_element.get('src'):
                        product_details['images']['specifications'] = urljoin(self.base_url, img_element['src'])
                
                # Tab wiring diagram (tab2)
                tab2 = tab_content.find('div', id='tab2')
                if tab2:
                    img_element = tab2.find('img')
                    if img_element and img_element.get('src'):
                        product_details['images']['wiring_diagram'] = urljoin(self.base_url, img_element['src'])
                
                # Tab dimensions (tab3)
                tab3 = tab_content.find('div', id='tab3')
                if tab3:
                    img_element = tab3.find('img')
                    if img_element and img_element.get('src'):
                        product_details['images']['dimensions'] = urljoin(self.base_url, img_element['src'])
            
            logger.info(f"Ho√†n th√†nh tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m: {product_code}")
            return product_details
            
        except Exception as e:
            logger.error(f"L·ªói khi tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m {product_code}: {e}")
            return {}
        finally:
            self.close_driver(driver)
    
    def translate_with_gemini(self, text: str, target_language: str = "Vietnamese") -> str:
        """
        D·ªãch vƒÉn b·∫£n b·∫±ng Gemini AI
        
        Args:
            text: VƒÉn b·∫£n c·∫ßn d·ªãch
            target_language: Ng√¥n ng·ªØ ƒë√≠ch
            
        Returns:
            VƒÉn b·∫£n ƒë√£ d·ªãch
        """
        if not self.gemini_model:
            logger.warning("Gemini AI kh√¥ng kh·∫£ d·ª•ng")
            return text
        
        try:
            prompt = f"Translate the following text to {target_language}: {text}"
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"L·ªói khi d·ªãch vƒÉn b·∫£n: {e}")
            return text
    
    def extract_specs_from_image_with_gemini(self, image_path: str, product_code: str) -> str:
        """
        Tr√≠ch xu·∫•t th√¥ng s·ªë k·ªπ thu·∫≠t t·ª´ ·∫£nh local b·∫±ng Gemini AI v√† t·∫°o b·∫£ng HTML
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n local c·ªßa ·∫£nh th√¥ng s·ªë k·ªπ thu·∫≠t
            product_code: M√£ s·∫£n ph·∫©m
            
        Returns:
            HTML table ch·ª©a th√¥ng s·ªë k·ªπ thu·∫≠t
        """
        if not self.gemini_model:
            logger.warning("Gemini AI kh√¥ng kh·∫£ d·ª•ng")
            return ""
        
        try:
            # Ki·ªÉm tra file t·ªìn t·∫°i
            image_file = Path(image_path)
            if not image_file.exists():
                logger.warning(f"File ·∫£nh kh√¥ng t·ªìn t·∫°i: {image_path}")
                return ""
            
            # ƒê·ªçc file ·∫£nh local
            with open(image_file, 'rb') as f:
                image_content = f.read()
            
            # Chuy·ªÉn ·∫£nh th√†nh base64
            image_data = base64.b64encode(image_content).decode()
            
            # X√°c ƒë·ªãnh MIME type d·ª±a tr√™n extension
            mime_type = "image/jpeg"
            if image_file.suffix.lower() in ['.png', '.webp']:
                mime_type = f"image/{image_file.suffix.lower()[1:]}"
            
            prompt = f"""
            Ph√¢n t√≠ch ·∫£nh th√¥ng s·ªë k·ªπ thu·∫≠t n√†y v√† tr√≠ch xu·∫•t t·∫•t c·∫£ th√¥ng tin k·ªπ thu·∫≠t.
            D·ªãch sang ti·∫øng Vi·ªát v√† t·∫°o b·∫£ng HTML theo ƒë·ªãnh d·∫°ng sau:
            
            <table id="specifications" border="1" cellpadding="8" cellspacing="0" style="border-collapse: collapse; font-family: Arial; width: 100%;">
            <thead>
            <tr style="background-color: #f2f2f2;">
            <th>Th√¥ng s·ªë</th>
            <th>Gi√° tr·ªã</th>
            </tr>
            </thead>
            <tbody>
            <tr><td style="font-weight: bold;">M√£ s·∫£n ph·∫©m</td><td>{product_code}</td></tr>
            [Th√™m c√°c th√¥ng s·ªë k·ªπ thu·∫≠t kh√°c ·ªü ƒë√¢y]
            <tr><td style="font-weight: bold;">Copyright</td><td>Haiphongtech.vn</td></tr>
            </tbody>
            </table>
            
            L∆∞u √Ω: 
            - H√†ng Copyright l√† b·∫Øt bu·ªôc ph·∫£i c√≥ cu·ªëi b·∫£ng.
            - CH·ªà TR·∫¢ V·ªÄ HTML TABLE THU·∫¶N T√öY, KH√îNG C√ì ```html, ```, ho·∫∑c b·∫•t k·ª≥ markdown formatting n√†o
            - Kh√¥ng th√™m text gi·∫£i th√≠ch ho·∫∑c m√¥ t·∫£ tr∆∞·ªõc/sau table
            """
            
            # G·ª≠i request t·ªõi Gemini v·ªõi ·∫£nh
            response = self.gemini_model.generate_content([
                prompt,
                {"mime_type": mime_type, "data": image_data}
            ])
            
            if response and response.text:
                # Lo·∫°i b·ªè markdown formatting n·∫øu c√≥
                html_content = response.text.strip()
                
                # Lo·∫°i b·ªè ```html v√† ``` n·∫øu c√≥
                if '```html' in html_content:
                    html_content = html_content.split('```html')[1].split('```')[0].strip()
                elif '```' in html_content:
                    html_content = html_content.replace('```', '').strip()
                
                # Lo·∫°i b·ªè c√°c text m√¥ t·∫£ th∆∞·ªùng g·∫∑p
                unwanted_texts = [
                    "Here's the HTML table representing the technical specifications from the image:",
                    "This HTML code creates a nicely formatted table with the technical specifications translated into Vietnamese.",
                    "Remember to replace",
                    "The table includes all the specifications from the image and the required copyright information.",
                    "D∆∞·ªõi ƒë√¢y l√† b·∫£ng HTML ch·ª©a th√¥ng s·ªë k·ªπ thu·∫≠t ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh, ƒë∆∞·ª£c d·ªãch sang ti·∫øng Vi·ªát:",
                    "with the actual product code if it's different"
                ]
                
                for unwanted in unwanted_texts:
                    if unwanted in html_content:
                        html_content = html_content.replace(unwanted, "").strip()
                
                logger.info(f"ƒê√£ tr√≠ch xu·∫•t th√¥ng s·ªë k·ªπ thu·∫≠t cho s·∫£n ph·∫©m {product_code}")
                return html_content
            else:
                logger.warning(f"Gemini kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ cho {product_code}")
                return ""
            
        except Exception as e:
            logger.error(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng s·ªë t·ª´ ·∫£nh {image_path}: {e}")
            return ""
    
    def fix_vietnamese_name_with_gemini(self, english_name: str) -> str:
        """
        S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ s·ª≠a v√† chu·∫©n h√≥a t√™n s·∫£n ph·∫©m ti·∫øng Vi·ªát + th√™m h·∫≠u t·ªë FOTEK
        
        Args:
            english_name: T√™n s·∫£n ph·∫©m ti·∫øng Anh
            
        Returns:
            T√™n s·∫£n ph·∫©m ti·∫øng Vi·ªát ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a + h·∫≠u t·ªë FOTEK
        """
        if not self.gemini_model:
            logger.warning("Gemini AI kh√¥ng kh·∫£ d·ª•ng")
            return f"{english_name} FOTEK"
        
        try:
            prompt = f"""
            D·ªãch t√™n s·∫£n ph·∫©m sau sang ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† ng·∫Øn g·ªçn nh·∫•t:
            "{english_name}"
            
            Y√™u c·∫ßu:
            - Ch·ªâ tr·∫£ v·ªÅ 1 t√™n duy nh·∫•t, kh√¥ng c√≥ c√°c l·ª±a ch·ªçn Option 1, 2, 3...
            - T√™n ph·∫£i ng·∫Øn g·ªçn, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu
            - Kh√¥ng th√™m text gi·∫£i th√≠ch ho·∫∑c m√¥ t·∫£
            - Kh√¥ng bao g·ªìm h·∫≠u t·ªë FOTEK (s·∫Ω ƒë∆∞·ª£c th√™m sau)
            - V√≠ d·ª•: "PS Series Inductive Proximity Sensor" ‚Üí "C·∫£m bi·∫øn ti·ªám c·∫≠n c·∫£m ·ª©ng d√≤ng PS"
            
            CH·ªà TR·∫¢ V·ªÄ T√äN TI·∫æNG VI·ªÜT DUY NH·∫§T:
            """
            
            response = self.gemini_model.generate_content(prompt)
            
            if response and response.text:
                vietnamese_name = response.text.strip()
                
                # Lo·∫°i b·ªè c√°c text kh√¥ng mong mu·ªën
                unwanted_patterns = [
                    "Option 1", "Option 2", "Option 3",
                    "**", "*", 
                    "There are several ways to translate",
                    "depending on the desired level",
                    "Formal", "less formal", "descriptive",
                    "suitable for technical documentation",
                    ">"
                ]
                
                for pattern in unwanted_patterns:
                    if pattern in vietnamese_name:
                        # L·∫•y ph·∫ßn ƒë·∫ßu ti√™n tr∆∞·ªõc khi g·∫∑p pattern
                        vietnamese_name = vietnamese_name.split(pattern)[0].strip()
                        break
                
                # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
                vietnamese_name = vietnamese_name.replace("*", "").replace(">", "").strip()
                
                # N·∫øu c√≥ nhi·ªÅu d√≤ng, ch·ªâ l·∫•y d√≤ng ƒë·∫ßu ti√™n
                if '\n' in vietnamese_name:
                    vietnamese_name = vietnamese_name.split('\n')[0].strip()
                
                # Th√™m h·∫≠u t·ªë FOTEK
                final_name = f"{vietnamese_name} FOTEK"
                
                logger.info(f"ƒê√£ s·ª≠a t√™n ti·∫øng Vi·ªát: {english_name} ‚Üí {final_name}")
                return final_name
            else:
                logger.warning(f"Gemini kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ cho t√™n: {english_name}")
                return f"{english_name} FOTEK"
                
        except Exception as e:
            logger.error(f"L·ªói khi s·ª≠a t√™n ti·∫øng Vi·ªát: {e}")
            return f"{english_name} FOTEK"
    
    def download_and_process_image(self, image_url: str, save_path: str, add_white_background: bool = False) -> bool:
        """
        T·∫£i xu·ªëng v√† x·ª≠ l√Ω ·∫£nh (chuy·ªÉn sang WebP, th√™m n·ªÅn tr·∫Øng n·∫øu c·∫ßn)
        
        Args:
            image_url: URL c·ªßa ·∫£nh
            save_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh
            add_white_background: C√≥ th√™m n·ªÅn tr·∫Øng kh√¥ng
            
        Returns:
            True n·∫øu th√†nh c√¥ng
        """
        try:
            response = self.safe_request(image_url)
            if not response:
                return False
            
            # M·ªü ·∫£nh
            original_image = Image.open(io.BytesIO(response.content))
            
            # Chuy·ªÉn sang RGBA n·∫øu c·∫ßn
            if original_image.mode != 'RGBA':
                original_image = original_image.convert('RGBA')
            
            processed_image = original_image
            
            # Th√™m n·ªÅn tr·∫Øng n·∫øu y√™u c·∫ßu
            if add_white_background:
                # T·∫°o ·∫£nh n·ªÅn tr·∫Øng c√πng k√≠ch th∆∞·ªõc
                white_background = Image.new('RGBA', original_image.size, (255, 255, 255, 255))
                # Gh√©p ·∫£nh g·ªëc l√™n n·ªÅn tr·∫Øng
                processed_image = Image.alpha_composite(white_background, original_image)
            
            # Chuy·ªÉn sang RGB ƒë·ªÉ l∆∞u WebP
            if processed_image.mode == 'RGBA':
                processed_image = processed_image.convert('RGB')
            
            # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
            save_path = Path(save_path)
            save_path.parent.mkdir(parents=True, exist_ok=True)
            
            # L∆∞u d∆∞·ªõi ƒë·ªãnh d·∫°ng WebP
            processed_image.save(save_path, 'WEBP', quality=85, optimize=True)
            
            logger.debug(f"ƒê√£ l∆∞u ·∫£nh: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {image_url}: {e}")
            return False
    
    def process_series_parallel(self, series_list: List[Dict]) -> List[Dict]:
        """
        X·ª≠ l√Ω nhi·ªÅu series song song b·∫±ng ƒëa lu·ªìng
        
        Args:
            series_list: Danh s√°ch series c·∫ßn x·ª≠ l√Ω
            
        Returns:
            Danh s√°ch t·∫•t c·∫£ s·∫£n ph·∫©m t·ª´ c√°c series
        """
        all_products = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit c√°c task
            future_to_series = {
                executor.submit(self.extract_products_from_series, series['url']): series
                for series in series_list
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for future in as_completed(future_to_series):
                series = future_to_series[future]
                try:
                    products = future.result()
                    for product in products:
                        product['series_name'] = series['name']
                        product['series_image'] = series['image']
                    all_products.extend(products)
                    logger.info(f"Ho√†n th√†nh series: {series['name']} - {len(products)} s·∫£n ph·∫©m")
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω series {series['name']}: {e}")
        
        return all_products
    
    def process_products_parallel(self, products_list: List[Dict]) -> List[Dict]:
        """
        X·ª≠ l√Ω chi ti·∫øt nhi·ªÅu s·∫£n ph·∫©m song song b·∫±ng ƒëa lu·ªìng
        
        Args:
            products_list: Danh s√°ch s·∫£n ph·∫©m c·∫ßn x·ª≠ l√Ω chi ti·∫øt
            
        Returns:
            Danh s√°ch s·∫£n ph·∫©m ƒë√£ x·ª≠ l√Ω chi ti·∫øt
        """
        detailed_products = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit c√°c task
            future_to_product = {
                executor.submit(self.extract_product_details, product['url'], product['code']): product
                for product in products_list
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for future in as_completed(future_to_product):
                base_product = future_to_product[future]
                try:
                    detailed_product = future.result()
                    if detailed_product:
                        # Merge th√¥ng tin c∆° b·∫£n v·ªõi chi ti·∫øt
                        detailed_product.update(base_product)
                        detailed_products.append(detailed_product)
                        logger.info(f"Ho√†n th√†nh chi ti·∫øt s·∫£n ph·∫©m: {detailed_product['code']}")
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω chi ti·∫øt s·∫£n ph·∫©m {base_product['code']}: {e}")
        
        return detailed_products
    
    def process_images_parallel(self, products_list: List[Dict]) -> List[Dict]:
        """
        X·ª≠ l√Ω t·∫£i xu·ªëng v√† chuy·ªÉn ƒë·ªïi ·∫£nh song song
        
        Args:
            products_list: Danh s√°ch s·∫£n ph·∫©m c√≥ ch·ª©a URLs ·∫£nh
            
        Returns:
            Danh s√°ch s·∫£n ph·∫©m ƒë√£ c·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n ·∫£nh local
        """
        def download_product_images(product):
            """Download v√† x·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh c·ªßa m·ªôt s·∫£n ph·∫©m v·ªõi c·∫•u tr√∫c file ƒë∆°n gi·∫£n"""
            product_code = product['code']
            
            # ƒê·∫£m b·∫£o th∆∞ m·ª•c images t·ªìn t·∫°i
            self.images_dir.mkdir(parents=True, exist_ok=True)
            
            updated_product = product.copy()
            
            # X·ª≠ l√Ω ·∫£nh s·∫£n ph·∫©m (th√™m n·ªÅn tr·∫Øng)
            if product['images']['product']:
                product_images_local = []
                for i, img_url in enumerate(product['images']['product']):
                    # Ch·ªâ l·∫•y ·∫£nh ƒë·∫ßu ti√™n v√† ƒë·∫∑t t√™n theo m√£ s·∫£n ph·∫©m
                    if i == 0:  # Ch·ªâ l·∫•y ·∫£nh ƒë·∫ßu ti√™n
                        filename = f"{product_code}.webp"
                        save_path = self.images_dir / filename
                        if self.download_and_process_image(img_url, str(save_path), add_white_background=True):
                            product_images_local.append(str(save_path))
                updated_product['images']['product'] = product_images_local
            
            # X·ª≠ l√Ω ·∫£nh th√¥ng s·ªë k·ªπ thu·∫≠t
            if product['images']['specifications']:
                filename = f"{product_code}-SPEC.webp"
                save_path = self.images_dir / filename
                if self.download_and_process_image(product['images']['specifications'], str(save_path)):
                    updated_product['images']['specifications'] = str(save_path)
            
            # X·ª≠ l√Ω ·∫£nh wiring diagram
            if product['images']['wiring_diagram']:
                filename = f"{product_code}-WD.webp"
                save_path = self.images_dir / filename
                if self.download_and_process_image(product['images']['wiring_diagram'], str(save_path)):
                    updated_product['images']['wiring_diagram'] = str(save_path)
            
            # X·ª≠ l√Ω ·∫£nh dimensions
            if product['images']['dimensions']:
                filename = f"{product_code}-DMS.webp"
                save_path = self.images_dir / filename
                if self.download_and_process_image(product['images']['dimensions'], str(save_path)):
                    updated_product['images']['dimensions'] = str(save_path)
            
            return updated_product
        
        processed_products = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit c√°c task download ·∫£nh
            future_to_product = {
                executor.submit(download_product_images, product): product
                for product in products_list
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for future in as_completed(future_to_product):
                original_product = future_to_product[future]
                try:
                    processed_product = future.result()
                    processed_products.append(processed_product)
                    logger.info(f"Ho√†n th√†nh x·ª≠ l√Ω ·∫£nh: {processed_product['code']}")
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh s·∫£n ph·∫©m {original_product['code']}: {e}")
        
        return processed_products
    
    def process_ai_tasks_parallel(self, products_list: List[Dict]) -> List[Dict]:
        """
        X·ª≠ l√Ω c√°c t√°c v·ª• AI (d·ªãch, tr√≠ch xu·∫•t th√¥ng s·ªë) song song
        
        Args:
            products_list: Danh s√°ch s·∫£n ph·∫©m c·∫ßn x·ª≠ l√Ω AI
            
        Returns:
            Danh s√°ch s·∫£n ph·∫©m ƒë√£ x·ª≠ l√Ω AI
        """
        def process_ai_for_product(product):
            """X·ª≠ l√Ω AI cho m·ªôt s·∫£n ph·∫©m"""
            updated_product = product.copy()
            
            # D·ªãch t√™n s·∫£n ph·∫©m sang ti·∫øng Vi·ªát
            if product['name']:
                vietnamese_name = self.translate_with_gemini(product['name'])
                updated_product['name_vietnamese'] = vietnamese_name
            
            # Tr√≠ch xu·∫•t th√¥ng s·ªë k·ªπ thu·∫≠t t·ª´ ·∫£nh
            if product['images']['specifications']:
                specs_table = self.extract_specs_from_image_with_gemini(
                    product['images']['specifications'], 
                    product['code']
                )
                updated_product['specifications_table'] = specs_table
            
            return updated_product
        
        if not self.gemini_model:
            logger.warning("Gemini AI kh√¥ng kh·∫£ d·ª•ng - b·ªè qua x·ª≠ l√Ω AI")
            return products_list
        
        processed_products = []
        
        with ThreadPoolExecutor(max_workers=min(self.max_workers, 3)) as executor:  # Gi·ªõi h·∫°n cho AI
            # Submit c√°c task AI
            future_to_product = {
                executor.submit(process_ai_for_product, product): product
                for product in products_list
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for future in as_completed(future_to_product):
                original_product = future_to_product[future]
                try:
                    processed_product = future.result()
                    processed_products.append(processed_product)
                    logger.info(f"Ho√†n th√†nh x·ª≠ l√Ω AI: {processed_product['code']}")
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω AI s·∫£n ph·∫©m {original_product['code']}: {e}")
                    processed_products.append(original_product)  # Gi·ªØ b·∫£n g·ªëc n·∫øu l·ªói
        
        return processed_products
    
    def save_to_excel(self, products_list: List[Dict], filename: str):
        """
        L∆∞u d·ªØ li·ªáu s·∫£n ph·∫©m v√†o file Excel
        
        Args:
            products_list: Danh s√°ch s·∫£n ph·∫©m
            filename: T√™n file Excel
        """
        try:
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho Excel
            excel_data = []
            
            for product in products_list:
                row = {
                    'M√£ s·∫£n ph·∫©m': product.get('code', ''),
                    'T√™n s·∫£n ph·∫©m (English)': product.get('name', ''),
                    'T√™n s·∫£n ph·∫©m (Ti·∫øng Vi·ªát)': product.get('name_vietnamese', ''),
                    'Series': product.get('series_name', ''),
                    'Nh√≥m s·∫£n ph·∫©m': product.get('group_name', ''),
                    'M√¥ t·∫£ t√≠nh nƒÉng': product.get('features', ''),
                    'URL s·∫£n ph·∫©m': product.get('url', ''),
                    '·∫¢nh s·∫£n ph·∫©m': ', '.join(product.get('images', {}).get('product', [])),
                    '·∫¢nh th√¥ng s·ªë k·ªπ thu·∫≠t': product.get('images', {}).get('specifications', ''),
                    '·∫¢nh s∆° ƒë·ªì ƒë·∫•u n·ªëi': product.get('images', {}).get('wiring_diagram', ''),
                    '·∫¢nh k√≠ch th∆∞·ªõc': product.get('images', {}).get('dimensions', ''),
                    'Th√¥ng s·ªë k·ªπ thu·∫≠t (HTML)': product.get('specifications_table', '')
                }
                excel_data.append(row)
            
            # T·∫°o DataFrame v√† l∆∞u Excel
            df = pd.DataFrame(excel_data)
            excel_path = self.excel_dir / filename
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='S·∫£n ph·∫©m', index=False)
                
                # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh ƒë·ªô r·ªông c·ªôt
                worksheet = writer.sheets['S·∫£n ph·∫©m']
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
            
            logger.info(f"ƒê√£ l∆∞u d·ªØ li·ªáu v√†o Excel: {excel_path}")
            
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u Excel: {e}")
    
    def save_products_by_category(self, products_list: List[Dict]) -> None:
        """
        L∆∞u d·ªØ li·ªáu s·∫£n ph·∫©m th√†nh c√°c file Excel ri√™ng theo danh m·ª•c
        
        Args:
            products_list: Danh s√°ch s·∫£n ph·∫©m
        """
        try:
            # T·∫°o th∆∞ m·ª•c Excel categories
            excel_categories_dir = self.output_dir / "excel_categories"
            excel_categories_dir.mkdir(exist_ok=True, parents=True)
            
            # Nh√≥m s·∫£n ph·∫©m theo category URL t·ª´ series_url
            category_groups = {}
            
            for product in products_list:
                series_url = product.get('series_url', '')
                
                # Tr√≠ch xu·∫•t category ID t·ª´ series URL
                # V√≠ d·ª•: https://www.fotek.com.tw/en-gb/product-category/72/113 ‚Üí category 72
                try:
                    if '/product-category/' in series_url:
                        category_part = series_url.split('/product-category/')[1]
                        category_id = category_part.split('/')[0]
                        
                        if category_id not in category_groups:
                            category_groups[category_id] = []
                        category_groups[category_id].append(product)
                except:
                    # N·∫øu kh√¥ng parse ƒë∆∞·ª£c, ƒë·∫∑t v√†o nh√≥m "unknown"
                    if 'unknown' not in category_groups:
                        category_groups['unknown'] = []
                    category_groups['unknown'].append(product)
            
            # L∆∞u t·ª´ng category th√†nh file Excel ri√™ng
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            for category_id, category_products in category_groups.items():
                if not category_products:
                    continue
                    
                # Chu·∫©n b·ªã d·ªØ li·ªáu cho Excel
                excel_data = []
                
                for product in category_products:
                    row = {
                        'M√£ s·∫£n ph·∫©m': product.get('code', ''),
                        'T√™n s·∫£n ph·∫©m (English)': product.get('name', ''),
                        'T√™n s·∫£n ph·∫©m (Ti·∫øng Vi·ªát)': product.get('name_vietnamese', ''),
                        'Series': product.get('series_name', ''),
                        'Nh√≥m s·∫£n ph·∫©m': product.get('group_name', ''),
                        'M√¥ t·∫£ t√≠nh nƒÉng': product.get('features', ''),
                        'URL s·∫£n ph·∫©m': product.get('url', ''),
                        '·∫¢nh s·∫£n ph·∫©m': ', '.join(product.get('images', {}).get('product', [])),
                        '·∫¢nh th√¥ng s·ªë k·ªπ thu·∫≠t': product.get('images', {}).get('specifications', ''),
                        '·∫¢nh s∆° ƒë·ªì ƒë·∫•u n·ªëi': product.get('images', {}).get('wiring_diagram', ''),
                        '·∫¢nh k√≠ch th∆∞·ªõc': product.get('images', {}).get('dimensions', ''),
                        'Th√¥ng s·ªë k·ªπ thu·∫≠t (HTML)': product.get('specifications_table', '')
                    }
                    excel_data.append(row)
                
                # T·∫°o DataFrame v√† l∆∞u Excel
                df = pd.DataFrame(excel_data)
                filename = f"fotek_category_{category_id}_{timestamp}.xlsx"
                excel_path = excel_categories_dir / filename
                
                with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                    df.to_excel(writer, sheet_name='S·∫£n ph·∫©m', index=False)
                    
                    # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh ƒë·ªô r·ªông c·ªôt
                    worksheet = writer.sheets['S·∫£n ph·∫©m']
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
                
                logger.info(f"ƒê√£ l∆∞u category {category_id}: {len(category_products)} s·∫£n ph·∫©m ‚Üí {excel_path}")
            
            logger.info(f"Ho√†n th√†nh l∆∞u {len(category_groups)} file Excel theo category v√†o: {excel_categories_dir}")
            
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u Excel theo category: {e}")
    
    def process_single_product_reprocess(self, row_data: tuple) -> Dict:
        """
        X·ª≠ l√Ω m·ªôt s·∫£n ph·∫©m ƒë∆°n l·∫ª trong qu√° tr√¨nh reprocess (thread-safe)
        
        Args:
            row_data: Tuple ch·ª©a (index, row) t·ª´ DataFrame
            
        Returns:
            Dict ch·ª©a th√¥ng tin s·∫£n ph·∫©m ƒë√£ x·ª≠ l√Ω
        """
        idx, row = row_data
        
        try:
            product_code = row['M√£ s·∫£n ph·∫©m']
            english_name = row['T√™n s·∫£n ph·∫©m (English)']
            
            logger.info(f"[{idx+1}] X·ª≠ l√Ω l·∫°i s·∫£n ph·∫©m: {product_code}")
            
            # 1. S·ª≠a t√™n ti·∫øng Vi·ªát v·ªõi Gemini
            vietnamese_name = self.fix_vietnamese_name_with_gemini(english_name)
            
            # 2. X·ª≠ l√Ω l·∫°i specs HTML t·ª´ ·∫£nh
            specs_html = ""
            spec_image_path = row.get('·∫¢nh th√¥ng s·ªë k·ªπ thu·∫≠t', '')
            
            if spec_image_path and Path(spec_image_path).exists():
                logger.info(f"ƒêang d·ªãch l·∫°i th√¥ng s·ªë k·ªπ thu·∫≠t cho {product_code}...")
                specs_html = self.extract_specs_from_image_with_gemini(spec_image_path, product_code)
            
            # T·∫°o l·∫°i object s·∫£n ph·∫©m
            product = {
                'code': product_code,
                'name': english_name,
                'name_vietnamese': vietnamese_name,
                'series_name': row.get('Series', ''),
                'group_name': row.get('Nh√≥m s·∫£n ph·∫©m', ''),
                'features': row.get('M√¥ t·∫£ t√≠nh nƒÉng', ''),
                'url': row.get('URL s·∫£n ph·∫©m', ''),
                'series_url': f"https://www.fotek.com.tw/en-gb/product-category/{row.get('Category_ID', 'unknown')}",  # T·∫°m th·ªùi
                'images': {
                    'product': [row.get('·∫¢nh s·∫£n ph·∫©m', '')] if row.get('·∫¢nh s·∫£n ph·∫©m', '') else [],
                    'specifications': spec_image_path,
                    'wiring_diagram': row.get('·∫¢nh s∆° ƒë·ªì ƒë·∫•u n·ªëi', ''),
                    'dimensions': row.get('·∫¢nh k√≠ch th∆∞·ªõc', '')
                },
                'specifications_table': specs_html
            }
            
            return product
            
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω s·∫£n ph·∫©m {product_code}: {e}")
            return None

    def reprocess_existing_data(self, max_workers: int = 5) -> None:
        """
        X·ª≠ l√Ω l·∫°i d·ªØ li·ªáu hi·ªán c√≥ ƒë·ªÉ s·ª≠a t√™n ti·∫øng Vi·ªát v√† specs HTML v·ªõi ƒëa lu·ªìng
        Ch·ªâ l·∫•y l·∫°i ·∫£nh th√¥ng s·ªë k·ªπ thu·∫≠t ƒë·ªÉ d·ªãch l·∫°i
        
        Args:
            max_workers: S·ªë l∆∞·ª£ng worker threads t·ªëi ƒëa
        """
        try:
            # T√¨m file Excel m·ªõi nh·∫•t
            excel_files = list(self.excel_dir.glob("fotek_products_*.xlsx"))
            if not excel_files:
                logger.error("Kh√¥ng t√¨m th·∫•y file Excel n√†o ƒë·ªÉ x·ª≠ l√Ω l·∫°i!")
                return
            
            latest_excel = max(excel_files, key=lambda f: f.stat().st_mtime)
            logger.info(f"ƒêang x·ª≠ l√Ω l·∫°i d·ªØ li·ªáu t·ª´: {latest_excel}")
            
            # ƒê·ªçc d·ªØ li·ªáu hi·ªán c√≥
            df = pd.read_excel(latest_excel)
            
            total_products = len(df)
            processed_count = 0
            products_list = []
            
            logger.info(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω l·∫°i {total_products} s·∫£n ph·∫©m v·ªõi {max_workers} workers...")
            
            # T·∫°o danh s√°ch c√°c task (index, row)
            tasks = [(idx, row) for idx, row in df.iterrows()]
            
            # X·ª≠ l√Ω ƒëa lu·ªìng
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submit t·∫•t c·∫£ tasks
                future_to_task = {
                    executor.submit(self.process_single_product_reprocess, task): task 
                    for task in tasks
                }
                
                # Thu th·∫≠p k·∫øt qu·∫£
                for future in as_completed(future_to_task):
                    try:
                        product = future.result()
                        if product:
                            products_list.append(product)
                            processed_count += 1
                            
                            # Log ti·∫øn ƒë·ªô m·ªói 50 s·∫£n ph·∫©m (do ƒëa lu·ªìng n√™n log √≠t h∆°n)
                            if processed_count % 50 == 0:
                                logger.info(f"‚úÖ ƒê√£ x·ª≠ l√Ω {processed_count}/{total_products} s·∫£n ph·∫©m ({processed_count/total_products*100:.1f}%)")
                                
                    except Exception as e:
                        task = future_to_task[future]
                        logger.error(f"L·ªói khi x·ª≠ l√Ω task {task[0]}: {e}")
                        continue
            
            logger.info(f"üéâ Ho√†n th√†nh x·ª≠ l√Ω l·∫°i {processed_count}/{total_products} s·∫£n ph·∫©m")
            
            # L∆∞u th√†nh c√°c file Excel ri√™ng theo category
            if products_list:
                logger.info("üìä ƒêang l∆∞u th√†nh c√°c file Excel theo category...")
                self.save_products_by_category(products_list)
                logger.info("‚úÖ Ho√†n th√†nh x·ª≠ l√Ω l·∫°i d·ªØ li·ªáu!")
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!")
            
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω l·∫°i d·ªØ li·ªáu: {e}")
    
    def run_full_scraping(self, category_urls: List[str], selected_series_indices: List[int] = None) -> Dict:
        """
        Ch·∫°y to√†n b·ªô quy tr√¨nh c√†o d·ªØ li·ªáu cho nhi·ªÅu danh m·ª•c
        
        Args:
            category_urls: Danh s√°ch URL c√°c trang danh m·ª•c
            selected_series_indices: Danh s√°ch index c·ªßa series c·∫ßn c√†o (None = t·∫•t c·∫£)
            
        Returns:
            Dict ch·ª©a th·ªëng k√™ k·∫øt qu·∫£
        """
        start_time = time.time()
        results = {
            'categories_count': len(category_urls),
            'series_count': 0,
            'products_count': 0,
            'success_count': 0,
            'error_count': 0,
            'duration': 0
        }
        
        try:
            all_series = []
            
            # B∆∞·ªõc 1: Tr√≠ch xu·∫•t series t·ª´ t·∫•t c·∫£ c√°c danh m·ª•c
            logger.info("üîç B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t danh s√°ch series t·ª´ c√°c danh m·ª•c...")
            for category_url in category_urls:
                series_list = self.extract_series_links(category_url)
                all_series.extend(series_list)
                logger.info(f"ƒê√£ tr√≠ch xu·∫•t {len(series_list)} series t·ª´: {category_url}")
            
            if not all_series:
                logger.error("Kh√¥ng t√¨m th·∫•y series n√†o!")
                return results
            
            # Ch·ªçn series c·∫ßn x·ª≠ l√Ω
            if selected_series_indices:
                selected_series = [all_series[i] for i in selected_series_indices if 0 <= i < len(all_series)]
            else:
                selected_series = all_series
            
            results['series_count'] = len(selected_series)
            logger.info(f"S·∫Ω x·ª≠ l√Ω {len(selected_series)} series")
            
            # B∆∞·ªõc 2: Tr√≠ch xu·∫•t s·∫£n ph·∫©m t·ª´ c√°c series (song song)
            logger.info("üì¶ B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t s·∫£n ph·∫©m t·ª´ c√°c series...")
            all_products = self.process_series_parallel(selected_series)
            results['products_count'] = len(all_products)
            
            if not all_products:
                logger.error("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o!")
                return results
            
            logger.info(f"T√¨m th·∫•y t·ªïng c·ªông {len(all_products)} s·∫£n ph·∫©m")
            
            # B∆∞·ªõc 3: Tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m (song song)
            logger.info("üîç B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t chi ti·∫øt s·∫£n ph·∫©m...")
            detailed_products = self.process_products_parallel(all_products)
            
            # B∆∞·ªõc 4: X·ª≠ l√Ω ·∫£nh (song song)
            logger.info("üñºÔ∏è B·∫Øt ƒë·∫ßu x·ª≠ l√Ω v√† t·∫£i xu·ªëng ·∫£nh...")
            processed_products = self.process_images_parallel(detailed_products)
            
            # B∆∞·ªõc 5: X·ª≠ l√Ω AI (song song)
            if self.gemini_model:
                logger.info("ü§ñ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω AI (d·ªãch v√† tr√≠ch xu·∫•t th√¥ng s·ªë)...")
                processed_products = self.process_ai_tasks_parallel(processed_products)
            
            # B∆∞·ªõc 6: L∆∞u d·ªØ li·ªáu
            logger.info("üíæ ƒêang l∆∞u d·ªØ li·ªáu...")
            
            # L∆∞u JSON
            json_path = self.output_dir / "fotek_products.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(processed_products, f, ensure_ascii=False, indent=2)
            
            # L∆∞u Excel
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            excel_filename = f"fotek_products_{timestamp}.xlsx"
            self.save_to_excel(processed_products, excel_filename)
            
            results['success_count'] = len(processed_products)
            results['error_count'] = results['products_count'] - results['success_count']
            
            logger.info("‚úÖ Ho√†n th√†nh c√†o d·ªØ li·ªáu!")
            
        except Exception as e:
            logger.error(f"L·ªói trong qu√° tr√¨nh c√†o d·ªØ li·ªáu: {e}")
            results['error_count'] += 1
        
        finally:
            results['duration'] = time.time() - start_time
        
        return results